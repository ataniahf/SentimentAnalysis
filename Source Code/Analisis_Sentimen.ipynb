{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mPSKNYlb1a9F"
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.classify import util\n",
    "from sklearn import linear_model\n",
    "from numpy import array\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "more_stopword = ['di',\"ke\",'ber','mah','nya','pas','in','an','se']\n",
    "sastrawi_stopword = factory.get_stop_words()+more_stopword\n",
    "# sastrawi_stopword = factory.get_stop_words()\n",
    "    \n",
    "# create path url for each stopword\n",
    "path_stopwords = []\n",
    "\n",
    "# combine stopwords\n",
    "stopwords_l = sastrawi_stopword\n",
    "for path in path_stopwords:\n",
    "    response = requests.get(path)\n",
    "    stopwords_l += response.text.split('\\n')\n",
    "\n",
    "# create dictionary with unique stopword\n",
    "st_words = set(stopwords_l)\n",
    "\n",
    "# result stopwords\n",
    "stop_words = st_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tapi', 'sedangkan', 'kemana', 'sekitar', 'agak', 'daripada', 'masih', 'sambil', 'se', 'tetapi', 'antara', 'kecuali', 'kami', 'bisa', 'bahwa', 'anda', 'mari', 'demikian', 'namun', 'apakah', 'dst', 'setidaknya', 'nya', 'walau', 'apalagi', 'adalah', 'di', 'seraya', 'sementara', 'dahulu', 'yang', 'saja', 'kenapa', 'hanya', 'setelah', 'hal', 'seperti', 'setiap', 'guna', 'boleh', 'ok', 'oleh', 'lain', 'dalam', 'mah', 'melainkan', 'yakni', 'in', 'atau', 'tolong', 'supaya', 'ya', 'kita', 'anu', 'tanpa', 'seharusnya', 'yaitu', 'ber', 'pas', 'belum', 'seolah', 'bagaimanapun', 'demi', 'lagi', 'kah', 'dulunya', 'maka', 'ia', 'serta', 'sampai', 'bagi', 'dsb', 'dari', 'secara', 'amat', 'toh', 'para', 'terhadap', 'mengapa', 'sebab', 'dapat', 'sebelum', 'an', 'pun', 'nggak', 'oh', 'untuk', 'sudah', 'dimana', 'saat', 'itu', 'harus', 'kepada', 'karena', 'selagi', 'saya', 'pasti', 'begitu', 'ketika', 'telah', 'ingin', 'ke', 'menurut', 'dia', 'agar', 'tidak', 'jika', 'dua', 'itulah', 'kembali', 'sesuatu', 'sebetulnya', 'mereka', 'tentang', 'dll', 'akan', 'pula', 'dengan', 'tentu', 'pada', 'sebagai', 'sehingga', 'seterusnya', 'juga', 'dan', 'nanti', 'ini', 'selain', 'sesudah', 'ada'}\n"
     ]
    }
   ],
   "source": [
    "print(st_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Preprocessing\n",
    "\n",
    "def case_folding(text):\n",
    "    text = text.lower() # lowercase\n",
    "    return text\n",
    "\n",
    "def emoji(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r'', text) # Remove non ASCII chars\n",
    "    text = re.sub(r'(\\\\u[0-9A-Fa-f]+)', r'', text)\n",
    "    return text\n",
    "\n",
    "def cleaning_text(text):\n",
    "    # Cleaning text\n",
    "    text = re.sub(r'@[\\w]*', ' ', text) # Remove mention handle user (@)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r'\\\\u\\w\\w\\w\\w', '', text) # Remove link web\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'#([^\\s]+)', '', text) # Remove #tagger\n",
    "    text = re.sub(r\"[.,:;+!\\-_<^/=?\\\"'\\(\\)\\d\\*]\", \" \", text) # Remove simbol, angka dan karakter aneh\n",
    "    return text\n",
    "\n",
    "def replaceThreeOrMore(text):\n",
    "    # Pattern to look for three or more repetitions of any character, including newlines (contoh goool -> gol).\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\", text) #2 atau lebih\n",
    "    # return pattern.sub(r\"\\1\\1\", text) #3 atau lebih\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def convertToSlangword(text):\n",
    "    kamus_slangword = eval(open(\"kamus_normalisasi_baru.txt\").read()) # Membuka dictionary slangword\n",
    "    pattern = re.compile(r'\\b( ' + '|'.join (kamus_slangword.keys())+r')\\b') # Search pola kata (contoh kpn -> kapan)\n",
    "    content = [] # menginisialisasi data kosong untuk hasil normalisasi\n",
    "    for kata in text: #iterasi melaui setiap kata dalam teks\n",
    "        filteredSlang = pattern.sub(lambda x: kamus_slangword[x.group()],kata) # mengganti slangword berdasarkan pola regex yg telah ditentukan dan kamus slangword\n",
    "        content.append(filteredSlang.lower())#menambahkan kata yang telah di word normalisasi kedalam daftar content hurufnya kecil\n",
    "    text = content #mengganti text dengan content yang telah di word normalisasi\n",
    "    return text\n",
    "\n",
    "def remove_stopword(text, stop_words=stop_words):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "def stemming_and_lemmatization(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    return stemmer.stem(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skema Preprocessing\n",
    "\n",
    "def prepro_1(data):\n",
    "    data['text'] = data['comment'].astype(str)\n",
    "    data['Clean_Twt'] = data['comment'].apply(case_folding)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].apply(emoji)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].apply(cleaning_text)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].astype(str)\n",
    "    data['Repeat'] = data['Clean_Twt'].apply(replaceThreeOrMore)\n",
    "    data['Tokenize_Tweet'] = data['Repeat'].apply(tokenize).astype(str)\n",
    "    data['Slang_Tweet'] = data['Tokenize_Tweet'].apply(convertToSlangword)\n",
    "    data['Slang_Tweet'] = data['Tokenize_Tweet'].apply(\" \".join)\n",
    "    data['Stem'] = data['Slang_Tweet'].apply(stemming_and_lemmatization)\n",
    "    # data['Negasi'] = data['Slang_Tweet'].apply(ganti_negasi)\n",
    "    data['Stopwords'] = data['Stem'].apply(remove_stopword)\n",
    "    data['comment'] = data['Stopwords']\n",
    "    data = data[['comment','Sentiments','Label']]\n",
    "    return data\n",
    "    \n",
    "def prepro_2(data):\n",
    "    # data = str[data]\n",
    "    data['text'] = data['comment'].astype(str)\n",
    "    data['Clean_Twt'] = data['comment'].apply(case_folding)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].apply(emoji)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].apply(cleaning_text)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].astype(str)\n",
    "    data['Repeat'] = data['Clean_Twt'].apply(replaceThreeOrMore)\n",
    "    data['Tokenize_Tweet'] = data['Repeat'].apply(tokenize)\n",
    "    # data['Slang_Tweet'] = data['Tokenize_Tweet'].apply(convertToSlangword)\n",
    "    data['Slang_Tweet'] = data['Tokenize_Tweet'].apply(\" \".join)\n",
    "    data['Stem'] = data['Slang_Tweet'].apply(stemming_and_lemmatization)\n",
    "    # data['Negasi'] = data['Slang_Tweet'].apply(ganti_negasi)\n",
    "    data['Stopwords'] = data['Stem'].apply(remove_stopword)\n",
    "    data['comment'] = data['Stopwords']\n",
    "    data = data[['comment','Sentiments','Label']]\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skema Preprocessing ouput satu-satu\n",
    "\n",
    "def prepro_3(data):\n",
    "    data['text'] = data['comment'].astype(str)\n",
    "    data['Clean_Twt'] = data['comment'].apply(case_folding)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].apply(emoji)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].apply(cleaning_text)\n",
    "    data['Clean_Twt'] = data['Clean_Twt'].astype(str)\n",
    "    data['Repeat'] = data['Clean_Twt'].apply(replaceThreeOrMore)\n",
    "    data['Tokenize_Tweet'] = data['Repeat'].apply(tokenize)\n",
    "    data['Slang_Tweet'] = data['Tokenize_Tweet'].apply(convertToSlangword)\n",
    "    data['Slang_Tweet'] = data['Slang_Tweet'].apply(\" \".join)\n",
    "    data['Stem'] = data['Slang_Tweet'].apply(stemming_and_lemmatization)\n",
    "    # data['Negasi'] = data['Slang_Tweet'].apply(ganti_negasi)\n",
    "    data['Stopwords'] = data['Stem'].apply(remove_stopword)\n",
    "    data['comment'] = data['Stopwords']\n",
    "    data = data[['comment','Sentiments','Label']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "E5I4XlpADa-k",
    "outputId": "4ef6f558-9e25-408a-fefa-6136793d585d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini sama kaya anak aku kmrn cuma dikasih obat...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anak saya waktu demam diatas 40 sama pas test ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cu.suminar sekarang keadaannya gmn mom? Semog...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alhamdulillah skrg sudah sehat lagi momin ber...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betul.. anak2 saya semua ga sampe 40 tertanga...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anak harus d daftar kn dl BPJS drmom, jd terp...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mudah2 ank2 kita semua di jauhakan dri segala ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Patah tulang jg kak. Alhamdulillah kemarin ana...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@permaditya alhamdulillah semoga mom dan si ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anak waktu itu datang kondisinya menggigil, te...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  Sentiments    Label\n",
       "0   ini sama kaya anak aku kmrn cuma dikasih obat...           1  positif\n",
       "1  Anak saya waktu demam diatas 40 sama pas test ...           1  positif\n",
       "2  @cu.suminar sekarang keadaannya gmn mom? Semog...           1  positif\n",
       "3   alhamdulillah skrg sudah sehat lagi momin ber...           1  positif\n",
       "4   betul.. anak2 saya semua ga sampe 40 tertanga...           1  positif\n",
       "5   anak harus d daftar kn dl BPJS drmom, jd terp...           1  positif\n",
       "6  Mudah2 ank2 kita semua di jauhakan dri segala ...           1  positif\n",
       "7  Patah tulang jg kak. Alhamdulillah kemarin ana...           1  positif\n",
       "8  @permaditya alhamdulillah semoga mom dan si ke...           1  positif\n",
       "9  Anak waktu itu datang kondisinya menggigil, te...           1  positif"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('DataHasilLabelingFix.csv', encoding='latin-1')\n",
    "data = data[['comment','Sentiments','Label']]\n",
    "# data = data[['comment']]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positif    350\n",
       "netral     350\n",
       "negatif    350\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ini sama kaya anak aku kmrn cuma dikasih obat...</td>\n",
       "      <td>positif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anak saya waktu demam diatas 40 sama pas test ...</td>\n",
       "      <td>positif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cu.suminar sekarang keadaannya gmn mom? Semog...</td>\n",
       "      <td>positif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alhamdulillah skrg sudah sehat lagi momin ber...</td>\n",
       "      <td>positif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betul.. anak2 saya semua ga sampe 40 tertanga...</td>\n",
       "      <td>positif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment    Label  Sentiments\n",
       "0   ini sama kaya anak aku kmrn cuma dikasih obat...  positif           1\n",
       "1  Anak saya waktu demam diatas 40 sama pas test ...  positif           1\n",
       "2  @cu.suminar sekarang keadaannya gmn mom? Semog...  positif           1\n",
       "3   alhamdulillah skrg sudah sehat lagi momin ber...  positif           1\n",
       "4   betul.. anak2 saya semua ga sampe 40 tertanga...  positif           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.unique()\n",
    "data['Sentiments'] = data['Label'].map({'positif': 1, 'netral': 0, 'negatif': -1})\n",
    "data = data[['comment','Label', 'Sentiments']]\n",
    "data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepro_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lenovo\\hello_ds\\Analisis_Sentimen.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/hello_ds/Analisis_Sentimen.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prepro_1(data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepro_1' is not defined"
     ]
    }
   ],
   "source": [
    "prepro_1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gabungan = prepro_1(data)\n",
    "dt_gabungan.to_csv(\"DataHasilPrepro1.1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sama kaya anak aku kemarin kasih obat plg alha...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anak waktu demam atas sama pas test darah semu...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suminar sekarang bagaimana mom moga sehat momi...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alhamdulilah sekarang sehat momin berkat bpjs ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betul anak semua tangan baik bpjs</td>\n",
       "      <td>1</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>bukan pakai bpjs langsung rsud kalau kalau dar...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>lalu habis lihat total harga periksa sana sini...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>bpjs memang laknat rakyat rasa lelah lima tahu...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>astaghfirulah adzim peraturanya kok tambah tol...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>kalau semua masyarakat ikut bpjs kan lumayan b...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  Sentiments    Label\n",
       "0     sama kaya anak aku kemarin kasih obat plg alha...           1  positif\n",
       "1     anak waktu demam atas sama pas test darah semu...           1  positif\n",
       "2     suminar sekarang bagaimana mom moga sehat momi...           1  positif\n",
       "3     alhamdulilah sekarang sehat momin berkat bpjs ...           1  positif\n",
       "4                     betul anak semua tangan baik bpjs           1  positif\n",
       "...                                                 ...         ...      ...\n",
       "1045  bukan pakai bpjs langsung rsud kalau kalau dar...          -1  negatif\n",
       "1046  lalu habis lihat total harga periksa sana sini...          -1  negatif\n",
       "1047  bpjs memang laknat rakyat rasa lelah lima tahu...          -1  negatif\n",
       "1048  astaghfirulah adzim peraturanya kok tambah tol...          -1  negatif\n",
       "1049  kalau semua masyarakat ikut bpjs kan lumayan b...          -1  negatif\n",
       "\n",
       "[1050 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('DataHasilPreproBPJS.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sama kaya anak aku kemarin kasih obat plg alha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anak waktu demam atas sama pas test darah semu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suminar sekarang bagaimana mom moga sehat momi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alhamdulilah sekarang sehat momin berkat bpjs ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betul anak semua tangan baik bpjs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  Sentiments\n",
       "0  sama kaya anak aku kemarin kasih obat plg alha...           1\n",
       "1  anak waktu demam atas sama pas test darah semu...           1\n",
       "2  suminar sekarang bagaimana mom moga sehat momi...           1\n",
       "3  alhamdulilah sekarang sehat momin berkat bpjs ...           1\n",
       "4                  betul anak semua tangan baik bpjs           1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiments'] = data['Label'].map({'positif': 1, 'netral': 0, 'negatif': -1})\n",
    "data = data[['comment', 'Sentiments']]\n",
    "data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FYHCl8ad9jy3"
   },
   "source": [
    "**Pembagian Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "MKPZdHj79la2"
   },
   "outputs": [],
   "source": [
    "# Memisahkan data test dan train\n",
    "\n",
    "x_train,x_test,y_train, y_test = train_test_split(data['comment'], data['Sentiments'], test_size = 0.2, random_state = 42 )\n",
    "# random_state = 50 menyatakan adanya pengacakan pada data yang di split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train : 840\n",
      "X test : 210\n",
      "y train : 840\n",
      "y test : 210\n"
     ]
    }
   ],
   "source": [
    "print('X train :', len(x_train))\n",
    "print('X test :', len(x_test))\n",
    "print('y train :', len(y_train))\n",
    "print('y test :', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "nA6qwiQ69v93"
   },
   "outputs": [],
   "source": [
    "df_train= pd.DataFrame()\n",
    "df_train['comment'] = x_train\n",
    "df_train['Sentiments'] = y_train\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test['comment'] = x_test\n",
    "df_test['Sentiments'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    76\n",
       " 0    72\n",
       "-1    62\n",
       "Name: Sentiments, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Sentiments\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(r\"data_train_prepro1.csv\")\n",
    "df_test.to_csv(r\"data_test_prepro1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>salam sehat sahabat mohon maaf atas ketidaknya...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>mau operasi jantung daftar tunggu lama bulan b...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>kok mending besar iuranya sama semua mampu uru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>kalau bayar mandiri bagaimana</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>halo admin mau tanya kalau mau update kartu as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>bapak kurang lebih tahun lalu opname tindak be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>kerja bagaimana</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>kalau wajib punya asuransi bpjs sama bagus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>tenaga sehat jahat lebih ting berkas ketimbang...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>dulu habis caesar datang hari sabtu dini hari ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  Sentiments\n",
       "554   salam sehat sahabat mohon maaf atas ketidaknya...           0\n",
       "1012  mau operasi jantung daftar tunggu lama bulan b...          -1\n",
       "481   kok mending besar iuranya sama semua mampu uru...           0\n",
       "432                       kalau bayar mandiri bagaimana           0\n",
       "626   halo admin mau tanya kalau mau update kartu as...           0\n",
       "...                                                 ...         ...\n",
       "330   bapak kurang lebih tahun lalu opname tindak be...           1\n",
       "466                                     kerja bagaimana           0\n",
       "121          kalau wajib punya asuransi bpjs sama bagus           1\n",
       "1044  tenaga sehat jahat lebih ting berkas ketimbang...          -1\n",
       "860   dulu habis caesar datang hari sabtu dini hari ...          -1\n",
       "\n",
       "[840 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CiYVhZp097t6"
   },
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "RCcmOUho996G"
   },
   "outputs": [],
   "source": [
    "# Word Vectorization (TF-IDF)\n",
    "# untuk mendapatkan 50000 top term dengan term frequency terbesar.\n",
    "tfidf_vect = TfidfVectorizer(max_features = 5000,\n",
    "                            lowercase=False)\n",
    "train_X_tfidf = tfidf_vect.fit_transform(df_train['comment']) #melatih model training\n",
    "test_X_tfidf = tfidf_vect.transform(df_test['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle dengan word normalization\n",
    "tfidf = tfidf_vect\n",
    "pickle.dump(tfidf.vocabulary_,open(\"tfidfBPJS1.sav\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle tanpa word normalization\n",
    "tfidf = tfidf_vect\n",
    "pickle.dump(tfidf.vocabulary_,open(\"tfidfBPJS2.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(lowercase=False, max_features=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(lowercase=False, max_features=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(lowercase=False, max_features=5000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1731)\t0.2621501841988313\n",
      "  (0, 930)\t0.15868557708036207\n",
      "  (0, 2120)\t0.17141674804124063\n",
      "  (0, 456)\t0.27402989063563615\n",
      "  (0, 1803)\t0.1445510166061068\n",
      "  (0, 2067)\t0.21678346612003593\n",
      "  (0, 249)\t0.2907733964566314\n",
      "  (0, 161)\t0.21041788063959668\n",
      "  (0, 534)\t0.14638663286623568\n",
      "  (0, 850)\t0.22866317255684085\n",
      "  (0, 1253)\t0.22431235574932096\n",
      "  (0, 769)\t0.2529355680071211\n",
      "  (0, 435)\t0.2529355680071211\n",
      "  (0, 1091)\t0.17258005219008637\n",
      "  (0, 1786)\t0.15391552249552068\n",
      "  (0, 999)\t0.2621501841988313\n",
      "  (0, 137)\t0.21041788063959668\n",
      "  (0, 1171)\t0.24540667837783606\n",
      "  (0, 1314)\t0.1978072778413867\n",
      "  (0, 1800)\t0.19568914349152083\n",
      "  (0, 1865)\t0.10250625500119069\n",
      "  (0, 1807)\t0.19568914349152083\n",
      "  (1, 1239)\t0.35907611372891834\n",
      "  (1, 1871)\t0.37994773067238874\n",
      "  (1, 337)\t0.4792978495937372\n",
      "  :\t:\n",
      "  (837, 163)\t0.4260738078631673\n",
      "  (837, 901)\t0.2834952185678024\n",
      "  (837, 309)\t0.1503314823678718\n",
      "  (837, 1812)\t0.32151693876855897\n",
      "  (838, 2148)\t0.43474247131077703\n",
      "  (838, 1001)\t0.39194720122950977\n",
      "  (838, 259)\t0.40970884310500166\n",
      "  (838, 2109)\t0.34187994481795897\n",
      "  (838, 1432)\t0.36691357302373434\n",
      "  (838, 820)\t0.39194720122950977\n",
      "  (838, 1121)\t0.24677206092030413\n",
      "  (838, 1865)\t0.15325962817467378\n",
      "  (839, 1439)\t0.3092650262904114\n",
      "  (839, 502)\t0.3092650262904114\n",
      "  (839, 1797)\t0.3092650262904114\n",
      "  (839, 359)\t0.3092650262904114\n",
      "  (839, 1857)\t0.2914567232234007\n",
      "  (839, 1989)\t0.2914567232234007\n",
      "  (839, 680)\t0.24320492498352653\n",
      "  (839, 1676)\t0.23857741954197187\n",
      "  (839, 2039)\t0.22379933027223617\n",
      "  (839, 1286)\t0.2483780359446844\n",
      "  (839, 700)\t0.37498209119791487\n",
      "  (839, 438)\t0.21793454077182092\n",
      "  (839, 556)\t0.17769042919624486\n"
     ]
    }
   ],
   "source": [
    "print(train_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2130)\t0.19526695741642816\n",
      "  (0, 1927)\t0.18715713569069542\n",
      "  (0, 1865)\t0.31913357023141703\n",
      "  (0, 1828)\t0.2052783438908072\n",
      "  (0, 1812)\t0.2585047174640593\n",
      "  (0, 1773)\t0.2791743499085668\n",
      "  (0, 1242)\t0.3017557388357818\n",
      "  (0, 1116)\t0.12887142966226198\n",
      "  (0, 882)\t0.24806953620368483\n",
      "  (0, 862)\t0.1755740495228934\n",
      "  (0, 770)\t0.1935175619403686\n",
      "  (0, 610)\t0.5687596810403391\n",
      "  (0, 596)\t0.2030802088362045\n",
      "  (0, 309)\t0.12086889581713123\n",
      "  (0, 169)\t0.14586975515497963\n",
      "  (1, 2192)\t0.33906727705933914\n",
      "  (1, 2100)\t0.31954288109899964\n",
      "  (1, 2049)\t0.23893575100628797\n",
      "  (1, 1948)\t0.30569010170832206\n",
      "  (1, 1865)\t0.23906256341431079\n",
      "  (1, 1366)\t0.2615678758838307\n",
      "  (1, 1309)\t0.30569010170832206\n",
      "  (1, 1177)\t0.2949450512348477\n",
      "  (1, 904)\t0.2615678758838307\n",
      "  (1, 831)\t0.21198852420226463\n",
      "  :\t:\n",
      "  (207, 807)\t0.19119206013600795\n",
      "  (207, 731)\t0.3116524719065012\n",
      "  (207, 631)\t0.47213349624670314\n",
      "  (207, 596)\t0.22255603267561\n",
      "  (207, 309)\t0.0662302399655271\n",
      "  (207, 267)\t0.4319844914446401\n",
      "  (207, 211)\t0.1424941567720492\n",
      "  (208, 2144)\t0.4465933151051955\n",
      "  (208, 2059)\t0.2748391927347886\n",
      "  (208, 1955)\t0.3769154378676407\n",
      "  (208, 1576)\t0.25819912307631976\n",
      "  (208, 631)\t0.31880103864966125\n",
      "  (208, 389)\t0.4465933151051955\n",
      "  (208, 267)\t0.29169102732150964\n",
      "  (208, 253)\t0.2889917460378953\n",
      "  (208, 169)\t0.21588473438676753\n",
      "  (209, 2077)\t0.26856759425154697\n",
      "  (209, 1578)\t0.26856759425154697\n",
      "  (209, 1329)\t0.2519460447999884\n",
      "  (209, 1053)\t0.4330148168363588\n",
      "  (209, 1029)\t0.4945465572483727\n",
      "  (209, 528)\t0.37666736361261116\n",
      "  (209, 437)\t0.3228302658325176\n",
      "  (209, 200)\t0.2587858840056476\n",
      "  (209, 182)\t0.21707173733703375\n"
     ]
    }
   ],
   "source": [
    "print(test_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 2329)\n",
      "(210, 2329)\n"
     ]
    }
   ],
   "source": [
    "print(train_X_tfidf.shape)\n",
    "print(test_X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'salam': 1807, 'sehat': 1865, 'sahabat': 1800, 'mohon': 1314, 'maaf': 1171, 'atas': 137, 'ketidaknyamananya': 999, 'rujuk': 1786, 'laku': 1091, 'dasar': 435, 'indikasi': 769, 'medis': 1253, 'jelas': 850, 'dokter': 534, 'bagai': 161, 'bentuk': 249, 'tangan': 2067, 'sakit': 1803, 'derita': 456, 'terima': 2120, 'kasih': 930, 'rein': 1731, 'mau': 1241, 'operasi': 1454, 'jantung': 836, 'daftar': 423, 'tunggu': 2201, 'lama': 1093, 'bulan': 337, 'sekarat': 1871, 'mati': 1239, 'kok': 1029, 'mending': 1262, 'besar': 267, 'iuranya': 808, 'sama': 1812, 'semua': 1899, 'mampu': 1199, 'urus': 2240, 'langsung': 1100, 'bpjs': 309, 'bukti': 336, 'tinggal': 2150, 'sistem': 1957, 'atur': 140, 'kolom': 1031, 'kalau': 901, 'bayar': 211, 'mandiri': 1206, 'bagaimana': 162, 'halo': 689, 'admin': 15, 'tanya': 2077, 'update': 2236, 'kartu': 924, 'askes': 130, 'cara': 366, 'gimana': 663, 'alhamdulilah': 61, 'kmren': 1025, 'mulai': 1331, 'pemeriksan': 1545, 'lahir': 1086, 'ful': 626, 'cover': 408, 'layan': 1116, 'kompeten': 1035, 'oke': 1446, 'banget': 182, 'alamat': 52, 'ktp': 1069, 'beda': 219, 'kata': 933, 'sesuai': 1927, 'dukcapil': 554, 'benar': 243, 'dulu': 556, 'kelas': 951, 'pelayananya': 1537, 'baru': 200, 'nagih': 1346, 'orang': 1463, 'antri': 102, 'kemo': 959, 'cuci': 415, 'darah': 432, 'isdet': 798, 'duluan': 557, 'sekarang': 1870, 'dah': 426, 'aku': 47, 'pernah': 1580, 'klaim': 1014, 'kacamata': 888, 'gratis': 675, 'bagus': 163, 'frame': 622, 'milih': 1282, 'lebih': 1121, 'iya': 812, 'nmbah': 1411, 'nyata': 1431, 'memang': 1258, 'jadi': 816, 'senjata': 1905, 'paling': 1487, 'ampuh': 81, 'pungut': 1679, 'uang': 2208, 'rakyat': 1705, 'sat': 1828, 'utama': 2251, 'penguna': 1554, 'rumah': 1787, 'hadir': 683, 'program': 1657, 'rehab': 1730, 'rencana': 1740, 'tahap': 2058, 'banyak': 193, 'tagih': 2056, 'nunggak': 1423, 'bangkrut': 184, 'zaman': 2326, 'covid': 411, 'begini': 227, 'cimtizen': 392, 'kalian': 904, 'tahu': 2059, 'dimanfatkan': 497, 'masyarakat': 1232, 'salah': 1806, 'satu': 1830, 'ditangung': 521, 'sendiri': 1902, 'nah': 1347, 'jenis': 856, 'apa': 104, 'sih': 1941, 'yuk': 2324, 'simak': 1948, 'infografis': 775, 'rs': 1773, 'royal': 1770, 'surabaya': 2036, 'baik': 169, 'teman': 2104, 'rawat': 1720, 'sana': 1817, 'sembuh': 1890, 'meski': 1275, 'pakai': 1482, 'bersih': 262, 'soal': 1976, 'antre': 101, 'mana': 1202, 'cekat': 374, 'bijak': 279, 'nyeleneh': 1434, 'kali': 903, 'anak': 84, 'demam': 448, 'muntah': 1339, 'lalu': 1092, 'igd': 758, 'hasil': 706, 'lab': 1083, 'keluar': 953, 'diangap': 470, 'datang': 438, 'jam': 828, 'kerja': 984, 'heuheu': 722, 'aneh': 90, 'ah': 23, 'inti': 794, 'jangan': 834, 'penting': 1558, 'pihak': 1596, 'akhir': 38, 'rbuan': 1723, 'harap': 697, 'mutih': 1343, 'warga': 2278, 'kurang': 1079, 'berapa': 253, 'ngalamin': 1385, 'muas': 1327, 'bantu': 191, 'adik': 13, 'ponakan': 1631, 'kemarin': 957, 'inap': 768, 'terus': 2125, 'ibu': 750, 'ambeien': 75, 'rsud': 1779, 'purwodadi': 1684, 'awat': 149, 'hari': 700, 'tiap': 2139, 'tindak': 2146, 'tensi': 2111, 'naik': 1348, 'mungkin': 1337, 'minggu': 1286, 'gapapa': 639, 'suruh': 2039, 'pulang': 1676, 'normal': 1419, 'buset': 347, 'emis': 573, 'jalan': 826, 'awal': 146, 'bros': 320, 'pekanbaru': 1530, 'suster': 2043, 'ramah': 1706, 'bubarin': 327, 'waktu': 2272, 'selamat': 1878, 'siang': 1934, 'rubah': 1784, 'status': 2011, 'tnimenjadi': 2167, 'lewat': 1136, 'pandawa': 1492, 'tahun': 2060, 'punya': 1680, 'hamil': 692, 'manusia': 1214, 'indonesia': 770, 'hutang': 746, 'rem': 1738, 'kebijakanya': 941, 'pro': 1655, 'kena': 963, 'serang': 1917, 'jt': 869, 'paje': 1480, 'paksa': 1485, 'masuk': 1229, 'pelangaran': 1534, 'ham': 691, 'pak': 1481, 'obat': 1440, 'terkadang': 2122, 'muka': 1330, 'sering': 1919, 'buruk': 346, 'penangananya': 1548, 'heran': 719, 'mudah': 1329, 'malah': 1194, 'ngeluh': 1396, 'lupain': 1168, 'wajib': 2270, 'ingat': 779, 'mertua': 1274, 'semingu': 1892, 'sekali': 1869, 'biaya': 274, 'juta': 882, 'hitung': 729, 'kamu': 910, 'tahan': 2057, 'tuh': 2187, 'mumet': 1334, 'kalaupun': 902, 'jelek': 853, 'wajar': 2269, 'bukan': 334, 'premium': 1643, 'anggap': 93, 'asuransi': 135, 'rendah': 1741, 'fasilitas': 596, 'dong': 539, 'yha': 2317, 'protes': 1662, 'koar': 1027, 'sini': 1953, 'moga': 1312, 'selalu': 1877, 'gbu': 650, 'sangat': 1819, 'apakabar': 106, 'gaji': 631, 'tua': 2185, 'harga': 699, 'standar': 2006, 'subsidi': 2023, 'kecil': 946, 'kaya': 935, 'bodoh': 302, 'nyokap': 1437, 'otak': 1465, 'loh': 1155, 'bahkan': 166, 'bedah': 221, 'beri': 256, 'suport': 2034, 'berterimakasih': 265, 'hidup': 724, 'detik': 459, 'sory': 1991, 'buzer': 350, 'ye': 2316, 'sempat': 1895, 'coba': 401, 'periksa': 1574, 'gigi': 660, 'aktif': 44, 'kemudian': 962, 'keburu': 943, 'tunda': 2198, 'urgent': 2238, 'mitra': 1298, 'cimahi': 391, 'padahal': 1473, 'kis': 1011, 'istri': 802, 'dtks': 550, 'kan': 911, 'otomatis': 1466, 'pbi': 1524, 'aju': 31, 'dinsos': 504, 'kantor': 917, 'bpjskes': 310, 'tempat': 2107, 'bilang': 282, 'temen': 2105, 'menteri': 1270, 'marsekal': 1223, 'pertama': 1587, 'tni': 2166, 'budi': 330, 'satriyo': 1829, 'utomo': 2253, 'sp': 1995, 'kfr': 1002, 'mars': 1222, 'diskus': 518, 'dirjampelkes': 511, 'lily': 1141, 'kresnowati': 1063, 'kes': 986, 'perihal': 1573, 'pemanfatan': 1541, 'data': 437, 'papah': 1502, 'arti': 122, 'irt': 796, 'fre': 624, 'lansia': 1103, 'hebat': 711, 'nyaman': 1427, 'usg': 2246, 'sulit': 2028, 'gawat': 646, 'darurat': 434, 'omg': 1448, 'nyangka': 1429, 'temu': 2108, 'tulus': 2194, 'pahala': 1477, 'terimakasih': 2121, 'tugas': 2186, 'pasien': 1511, 'umum': 2223, 'rasa': 1717, 'eror': 579, 'esnawan': 583, 'sanggup': 1820, 'nunggu': 1424, 'akhirmya': 39, 'sia': 1933, 'swasta': 2046, 'antisipasi': 100, 'enak': 577, 'dmn': 529, 'puas': 1671, 'makanya': 1184, 'pesona': 1593, 'ganti': 637, 'faskes': 597, 'via': 2256, 'aplikasi': 112, 'pilih': 1598, 'anti': 99, 'saudara': 1831, 'batal': 204, 'domisili': 537, 'tny': 2168, 'ayah': 153, 'non': 1417, 'usaha': 2244, 'dftarkan': 464, 'kasus': 932, 'tambah': 2064, 'tks': 2161, 'info': 774, 'bahas': 165, 'kripto': 1065, 'tuju': 2189, 'berazas': 255, 'gotong': 672, 'royong': 1771, 'doa': 531, 'ikut': 762, 'nikmat': 1409, 'aka': 33, 'gantung': 638, 'ra': 1693, 'keluarga': 954, 'lancar': 1098, 'dilayanin': 495, 'diomongin': 506, 'butuh': 348, 'sila': 1942, 'khusus': 1006, 'alm': 68, 'bapak': 196, 'katup': 934, 'paham': 1478, 'si': 1932, 'rscm': 1775, 'suportif': 2035, 'wa': 2263, 'sedang': 1852, 'jkn': 862, 'mobile': 1306, 'nomor': 1416, 'hp': 734, 'email': 571, 'daftarin': 424, 'auto': 143, 'debit': 442, 'rekening': 1735, 'bawa': 207, 'abang': 0, 'tumor': 2196, 'colon': 404, 'primaya': 1650, 'bekas': 230, 'timur': 2145, 'pbyr': 1527, 'pribadi': 1647, 'reaktivasi': 1724, 'perintah': 1576, 'kenyat': 969, 'lapang': 1106, 'cek': 373, 'nik': 1408, 'denda': 450, 'seram': 1916, 'kondisi': 1039, 'alas': 56, 'menungak': 1272, 'salin': 1810, 'kluhan': 1019, 'kandunganya': 915, 'prnah': 1654, 'adan': 11, 'susah': 2041, 'usgin': 2247, 'bolak': 306, 'balik': 177, 'ngrus': 1401, 'puskesmas': 1688, 'misua': 1297, 'smpek': 1970, 'bulet': 339, 'bujuk': 332, 'kecewa': 945, 'rsab': 1774, 'harkit': 701, 'kagum': 894, 'by': 351, 'tap': 2078, 'emngnya': 574, 'wiraswasta': 2292, 'serabutan': 1914, 'tani': 2074, 'nelayan': 1374, 'jawab': 845, 'jamin': 831, 'wil': 2289, 'jabar': 814, 'nasib': 1365, 'gol': 669, 'tetap': 2130, 'prosedur': 1659, 'scaling': 1842, 'mengunakan': 1266, 'gila': 661, 'ku': 1070, 'peras': 1565, 'sekolah': 1874, 'pintar': 1604, 'blt': 296, 'biasa': 273, 'wah': 2266, 'crazy': 412, 'rich': 1763, 'jual': 870, 'tanah': 2065, 'ngurus': 1403, 'surat': 2037, 'kendaran': 968, 'pakenya': 1483, 'prematur': 1641, 'angkat': 95, 'placentanya': 1611, 'lepas': 1134, 'bayi': 213, 'dalem': 427, 'perut': 1590, 'potong': 1635, 'lumayan': 1163, 'kakak': 897, 'pikir': 1597, 'deket': 447, 'lebaran': 1120, 'huhuhu': 742, 'dinformasikan': 501, 'kepesertan': 975, 'hary': 705, 'barakalah': 198, 'umrik': 2222, 'abar': 1, 'murah': 1340, 'rezeki': 1755, 'bar': 197, 'traktir': 2173, 'jalur': 827, 'malas': 1197, 'ribetnya': 1761, 'wqwq': 2306, 'kontrol': 1048, 'wahyu': 2268, 'ow': 1471, 'phk': 1594, 'sempet': 1896, 'pkm': 1609, 'puji': 1674, 'tuhan': 2188, 'sc': 1841, 'dicover': 478, 'bilirubin': 283, 'tinggi': 2151, 'segala': 1859, 'macam': 1173, 'jahit': 821, 'gkda': 667, 'niat': 1407, 'tmn': 2165, 'nyaranin': 1430, 'sayang': 1833, 'dpke': 543, 'usia': 2249, 'mlai': 1302, 'rutin': 1793, 'hpl': 735, 'gda': 651, 'kontraksi': 1047, 'sesar': 1925, 'oprasi': 1459, 'drwat': 548, 'hri': 738, 'ribu': 1762, 'pampers': 1488, 'dewasa': 461, 'perban': 1567, 'air': 26, 'mantap': 1212, 'gatau': 643, 'asli': 131, 'keluh': 955, 'beli': 236, 'sabun': 1798, 'mandi': 1204, 'kasa': 927, 'sohib': 1981, 'berwirausaha': 266, 'penghitunganya': 1553, 'alur': 69, 'online': 1451, 'nder': 1368, 'bekeluarga': 231, 'masukin': 1230, 'pasang': 1509, 'bjs': 289, 'makin': 1187, 'kesini': 993, 'lumpuh': 1164, 'theraphy': 2136, 'tulang': 2191, 'gapernh': 640, 'peser': 1592, 'erti': 580, 'alamin': 54, 'kn': 1026, 'dl': 526, 'drmom': 544, 'pisah': 1606, 'ubah': 2209, 'nama': 1352, 'seluruh': 1886, 'cepat': 378, 'asal': 125, 'diri': 510, 'pensiun': 1557, 'kaca': 887, 'mata': 1235, 'optik': 1460, 'tunjuk': 2203, 'minta': 1289, 'tanda': 2066, 'nol': 1414, 'persen': 1582, 'ribet': 1759, 'purgoso': 1682, 'konsul': 1043, 'diagnosis': 466, 'alvonso': 70, 'kandung': 914, 'masalah': 1227, 'senua': 1907, 'marimar': 1219, 'saran': 1824, 'hapus': 696, 'rata': 1718, 'kompleks': 1037, 'tg': 2133, 'cukup': 418, 'point': 1621, 'jenjang': 857, 'sehinga': 1866, 'opini': 1457, 'apabila': 105, 'perlu': 1578, 'aman': 73, 'ganda': 635, 'pindah': 1600, 'mutasi': 1342, 'hei': 714, 'samaratakan': 1814, 'tara': 2079, 'yakin': 2311, 'sedia': 1856, 'kira': 1008, 'tabung': 2055, 'nambal': 1356, 'bolong': 308, 'sewot': 1930, 'hm': 731, 'framenya': 623, 'rugi': 1785, 'gampang': 634, 'rusak': 1791, 'banyumas': 194, 'margono': 1218, 'lah': 1085, 'eyang': 588, 'uti': 2252, 'kanker': 916, 'situ': 1959, 'habis': 680, 'masa': 1226, 'kontrak': 1046, 'pkwt': 1610, 'pt': 1668, 'iur': 807, 'lanjut': 1101, 'usus': 2250, 'buntu': 344, 'laparoskopi': 1107, 'sepenuh': 1912, 'aga': 20, 'rada': 1694, 'sepele': 1911, 'usah': 2243, 'brengsek': 318, 'system': 2051, 'huni': 745, 'sdm': 1847, 'bobrok': 299, 'payah': 1521, 'duit': 553, 'gilir': 662, 'hilangkanbpjs': 726, 'mengigil': 1265, 'bada': 159, 'panas': 1489, 'sdan': 1844, 'peduli': 1528, 'resiko': 1747, 'resep': 1746, 'haruske': 704, 'loket': 1156, 'os': 1464, 'fungsi': 627, 'percuma': 1570, 'rsu': 1778, 'sis': 1954, 'aldjufri': 59, 'penghargan': 1552, 'peringkat': 1575, 'badan': 160, 'penyelengara': 1560, 'sosial': 1992, 'pusat': 1686, 'tm': 2164, 'pelit': 1539, 'dekat': 446, 'lengkap': 1132, 'wek': 2283, 'dijadwalin': 486, 'karyawan': 926, 'pegawai': 1529, 'asn': 134, 'standard': 2007, 'gubernur': 677, 'dki': 525, 'bentur': 250, 'pres': 1644, 'ungkap': 2227, 'tian': 2138, 'diskusi': 519, 'publik': 1673, 'budhe': 329, 'std': 2012, 'plus': 1613, 'fisioterapi': 608, 'panti': 1501, 'rapi': 1715, 'yogya': 2319, 'kualitas': 1073, 'mumpuni': 1335, 'hukum': 744, 'hak': 687, 'asasi': 127, 'ambil': 76, 'langkah': 1099, 'administrasi': 16, 'kayan': 936, 'intelektual': 790, 'imigrasi': 766, 'komentar': 1032, 'bpjskesehatan': 311, 'umrah': 2221, 'sim': 1947, 'jualtanah': 871, 'belitanah': 240, 'naikhaji': 1349, 'skck': 1962, 'stnk': 2015, 'sukses': 2027, 'capai': 365, 'cakup': 361, 'semesta': 1891, 'kabupaten': 886, 'pemkab': 1546, 'lampung': 1097, 'selatan': 1881, 'raih': 1702, 'universal': 2228, 'health': 709, 'coverage': 409, 'uhc': 2213, 'sush': 2042, 'pandemi': 1493, 'kmarin': 1021, 'bidan': 277, 'sertifikat': 1922, 'rapat': 1714, 'dewi': 462, 'asmara': 133, 'seringkali': 1920, 'hadap': 682, 'izin': 813, 'purwokerto': 1685, 'far': 594, 'turut': 2206, 'alangkah': 55, 'telat': 2098, 'pagi': 1475, 'marah': 1215, 'drs': 547, 'viralkan': 2259, 'fb': 602, 'ramai': 1707, 'angar': 91, 'tanggung': 2072, 'negara': 1370, 'sisa': 1955, 'faskesnya': 598, 'per': 1563, 'trimester': 2180, 'fktp': 610, 'jejaring': 849, 'rekan': 1734, 'sebut': 1850, 'hitunganya': 730, 'jumlah': 878, 'perhati': 1572, 'kait': 895, 'skema': 1963, 'penjaminanya': 1556, 'patah': 1518, 'paha': 1476, 'presiden': 1645, 'cinta': 393, 'br': 316, 'syarat': 2049, 'lupa': 1167, 'penanguhan': 1549, 'virtual': 2260, 'acountnya': 7, 'kadaluarsa': 889, 'tulisanya': 2193, 'lunas': 1165, 'bandung': 180, 'hemp': 716, 'unsur': 2231, 'autodebet': 144, 'proses': 1660, 'jokowi': 867, 'hina': 727, 'hujat': 743, 'caci': 357, 'maki': 1186, 'lawan': 1115, 'buka': 333, 'praktek': 1637, 'tkp': 2160, 'set': 1928, 'mod': 1307, 'noh': 1413, 'benahin': 242, 'ketidakdisiplinan': 998, 'nasional': 1366, 'kencang': 966, 'misal': 1295, 'parah': 1503, 'perbln': 1568, 'tepat': 2112, 'bulanya': 338, 'rupa': 1790, 'suatu': 2020, 'penuh': 1559, 'trimakasih': 2179, 'main': 1179, 'lihat': 1140, 'realitas': 1725, 'biadab': 271, 'fitur': 609, 'solusi': 1985, 'sindonews': 1949, 'bukanberitabiasa': 335, 'pbin': 1525, 'nambah': 1355, 'anggota': 94, 'keteranganya': 997, 'tsb': 2184, 'muncul': 1336, 'digital': 484, 'percaya': 1569, 'nominal': 1415, 'kantung': 918, 'pusing': 1687, 'kota': 1059, 'priksa': 1649, 'cmiw': 400, 'diniatin': 503, 'amal': 72, 'alam': 51, 'op': 1453, 'bypas': 354, 'soetomo': 1978, 'iwan': 811, 'jajaranya': 823, 'luar': 1161, 'sby': 1840, 'balas': 175, 'pembiayan': 1544, 'tera': 2113, 'wara': 2276, 'wiri': 2293, 'kesel': 991, 'contoh': 407, 'paket': 1484, 'rp': 1772, 'bawah': 208, 'laman': 1094, 'sbs': 1838, 'lew': 1135, 'dirgahayu': 509, 'samarinda': 1815, 'id': 752, 'request': 1744, 'postingan': 1634, 'tungak': 2199, 'apbd': 108, 'apbn': 109, 'manual': 1213, 'cabang': 355, 'wilayah': 2291, 'sore': 1989, 'nanya': 1363, 'fakes': 590, 'register': 1727, 'logout': 1154, 'login': 1153, 'ulang': 2218, 'chat': 382, 'whatsap': 2284, 'makan': 1182, 'emosi': 575, 'plg': 1612, 'asa': 124, 'minimal': 1288, 'bru': 322, 'nganter': 1387, 'tetanga': 2129, 'sardjito': 1826, 'jogja': 864, 'stadium': 2004, 'bner': 297, 'sadar': 1799, 'bengkalai': 246, 'kuliah': 1076, 'maksimal': 1190, 'hinga': 728, 'lampir': 1096, 'terang': 2114, 'universitas': 2229, 'didik': 480, 'teri': 2118, 'sederhana': 1854, 'kejam': 949, 'sombong': 1986, 'poliklinik': 1628, 'ketidakpastian': 1000, 'visit': 2261, 'ruang': 1783, 'klasik': 1015, 'selesai': 1883, 'cekik': 375, 'leher': 1124, 'ikhas': 760, 'insha': 784, 'allah': 67, 'manfat': 1207, 'kesehatanya': 988, 'kader': 892, 'resmi': 1749, 'milik': 1283, 'peran': 1564, 'latih': 1112, 'unduh': 2225, 'mobil': 1305, 'kemudi': 961, 'revormasi': 1754, 'jilid': 859, 'kpn': 1061, 'rusuh': 1792, 'mr': 1323, 'ketemu': 995, 'blacklist': 292, 'vip': 2258, 'samarata': 1813, 'turun': 2204, 'rekomendasi': 1736, 'spesialis': 1999, 'riwayat': 1767, 'imbang': 764, 'testimoni': 2128, 'syubanul': 2052, 'wathon': 2279, 'al': 50, 'crew': 413, 'mindset': 1285, 'bengu': 247, 'nunjukin': 1425, 'dipalakin': 507, 'kamar': 906, 'kasi': 929, 'keren': 980, 'moveon': 1322, 'bung': 343, 'karno': 923, 'ngerawat': 1397, 'lembut': 1129, 'pasi': 1510, 'imo': 767, 'case': 369, 'riba': 1758, 'bapa': 195, 'cicalengka': 387, 'hernia': 721, 'jadwal': 818, 'lipom': 1148, 'ibarat': 748, 'pepatah': 1562, 'miskin': 1296, 'bisnis': 286, 'kla': 1013, 'pandang': 1491, 'belah': 234, 'miris': 1293, 'putus': 1691, 'hubung': 739, 'mua': 1326, 'ngutang': 1405, 'beban': 216, 'angep': 92, 'sedekah': 1853, 'janagn': 833, 'mbuat': 1248, 'ru': 1782, 'kesehatn': 989, 'brbasis': 317, 'kaji': 896, 'disayangkn': 515, 'pmbahasanya': 1614, 'buru': 345, 'halus': 690, 'embel': 572, 'cicil': 389, 'deh': 444, 'cari': 368, 'pintas': 1605, 'citra': 397, 'sifat': 1939, 'referensi': 1726, 'policy': 1627, 'masing': 1228, 'walaupun': 2273, 'amin': 78, 'tolol': 2171, 'melangar': 1256, 'asas': 126, 'adil': 14, 'hubunganya': 740, 'anjing': 97, 'bangsat': 186, 'keparat': 972, 'pererintah': 1571, 'lgsung': 1137, 'negeri': 1372, 'seberang': 1849, 'brobat': 319, 'konfirmasi': 1040, 'tata': 2087, 'nilai': 1410, 'hati': 707, 'rejeki': 1732, 'kunjung': 1077, 'jauhakan': 843, 'tumbuh': 2195, 'lsg': 1160, 'konyol': 1049, 'kerjasama': 985, 'bjps': 288, 'model': 1309, 'dimensi': 498, 'transfusi': 2175, 'suami': 2019, 'dikit': 493, 'wlpun': 2302, 'lwat': 1170, 'sebal': 1848, 'blangko': 293, 'temenku': 2106, 'nhs': 1406, 'london': 1158, 'jadul': 817, 'kirim': 1010, 'foto': 618, 'acung': 9, 'jempol': 855, 'oen': 1445, 'solo': 1984, 'ngebedain': 1392, 'uki': 2217, 'yadika': 2309, 'jakarta': 824, 'polri': 1630, 'nakesnya': 1351, 'smrg': 1971, 'yangtiku': 2314, 'rsmc': 1777, 'telogorejo': 2101, 'rampok': 1709, 'pajak': 1479, 'laknat': 1089, 'lelah': 1126, 'lima': 1142, 'nyesek': 1436, 'kejang': 950, 'anjg': 96, 'ratus': 1719, 'jiwa': 861, 'butuhin': 349, 'jahat': 820, 'preman': 1640, 'kedok': 947, 'kalang': 900, 'asih': 129, 'otoritas': 1468, 'susun': 2044, 'formula': 616, 'prinsip': 1651, 'betul': 269, 'sedikit': 1858, 'jauh': 842, 'nge': 1391, 'print': 1652, 'sejak': 1868, 'komplain': 1036, 'benefit': 245, 'jebol': 848, 'defisit': 443, 'senang': 1901, 'awas': 148, 'baca': 157, 'mesti': 1276, 'rban': 1722, 'kb': 937, 'batas': 205, 'kualat': 1072, 'baitulah': 170, 'mahal': 1175, 'dompet': 538, 'mhl': 1279, 'murh': 1341, 'stiap': 2014, 'ngukurnya': 1402, 'behbeh': 229, 'tim': 2143, 'staf': 2005, 'arah': 118, 'joko': 866, 'widodo': 2288, 'bersatulawancovid': 261, 'ksp': 1067, 'rangka': 1711, 'survey': 2040, 'pelang': 1533, 'media': 1251, 'isi': 800, 'link': 1146, 'ci': 385, 'nps': 1420, 'nanda': 1357, 'betambah': 268, 'setor': 1929, 'jelata': 852, 'pmk': 1615, 'no': 1412, 'tarif': 2082, 'lengar': 1131, 'taraf': 2080, 'intern': 792, 'jodoh': 863, 'alias': 63, 'tiri': 2156, 'tes': 2126, 'opname': 1458, 'bicara': 276, 'ajak': 28, 'puasa': 1672, 'belibet': 238, 'seminguan': 1893, 'jaga': 819, 'selang': 1879, 'seling': 1884, 'ajar': 29, 'duduk': 551, 'belakang': 235, 'suru': 2038, 'tega': 2094, 'dengar': 452, 'statement': 2009, 'kaget': 893, 'intimidasi': 795, 'maupun': 1242, 'peluang': 1540, 'kelola': 952, 'bangladesh': 185, 'akselerasi': 41, 'tingkat': 2152, 'pengelolan': 1551, 'naudzubilah': 1367, 'blg': 294, 'bius': 287, 'total': 2172, 'cabut': 356, 'babi': 156, 'btw': 323, 'bunda': 342, 'terapi': 2116, 'kembang': 958, 'bayang': 209, 'mulu': 1332, 'digalakin': 483, 'umur': 2224, 'itungan': 806, 'singapore': 1952, 'galak': 632, 'wkwkwkw': 2297, 'minus': 1291, 'lipat': 1147, 'syukur': 2053, 'aji': 30, 'janji': 835, 'kampanye': 908, 'ampun': 82, 'jabat': 815, 'skrng': 1965, 'cicendo': 388, 'miop': 1292, 'informasi': 776, 'cetak': 380, 'henti': 718, 'dijatahin': 488, 'usgnya': 2248, 'tis': 2157, 'smua': 1973, 'pempes': 1547, 'trgantung': 2177, 'pkai': 1608, 'bedakn': 222, 'pabrik': 1472, 'pers': 1581, 'ugd': 2211, 'pelayana': 1535, 'mahasiswa': 1177, 'uin': 2214, 'ar': 117, 'raniry': 1712, 'aceh': 6, 'aktifin': 45, 'nonaktif': 1418, 'gaes': 630, 'serius': 1921, 'ngaco': 1382, 'ayo': 154, 'pola': 1625, 'pasienginjal': 1512, 'ahli': 25, 'gizi': 666, 'pantau': 1500, 'lindung': 1144, 'ginjal': 665, 'pasword': 1517, 'menit': 1267, 'rekrutmen': 1737, 'seleksi': 1882, 'aktuaris': 46, 'ajun': 32, 'fokus': 613, 'pesan': 1591, 'bekerjasama': 232, 'toko': 2169, 'demonstrasi': 449, 'wakil': 2271, 'sesi': 1926, 'inovation': 783, 'zone': 2327, 'wsf': 2307, 'diselengarakan': 516, 'isa': 797, 'maroko': 1221, 'usahakn': 2245, 'trjadi': 2182, 'bpjsnya': 315, 'obgynku': 1442, 'hehe': 712, 'wlopun': 2301, 'kmauan': 1022, 'sndri': 1975, 'pngalamanku': 1616, 'suka': 2025, 'ksih': 1066, 'lncr': 1152, 'jaya': 847, 'netizen': 1380, 'ulit': 2219, 'bea': 215, 'cukai': 417, 'korupsi': 1057, 'kepsertan': 977, 'sepakat': 1910, 'manfatkan': 1208, 'byar': 353, 'ngaruh': 1390, 'kepo': 976, 'ngapain': 1388, 'mikir': 1281, 'ribetin': 1760, 'perkara': 1577, 'nyambung': 1428, 'mkin': 1299, 'lma': 1151, 'tarik': 2083, 'thanks': 2134, 'for': 614, 'mom': 1315, 'depok': 455, 'bekersama': 233, 'pilote': 1599, 'konsultasi': 1044, 'silah': 1943, 'profesional': 1656, 'bedan': 223, 'hancur': 694, 'teriak': 2119, 'ampas': 80, 'umbulharjo': 2220, 'mei': 1255, 'lair': 1087, 'klinik': 1017, 'kakung': 899, 'stres': 2018, 'panik': 1497, 'ngeluarin': 1395, 'cair': 360, 'lantai': 1104, 'sblmnya': 1836, 'ngedadak': 1393, 'lari': 1111, 'kmna': 1024, 'kmi': 1023, 'april': 116, 'segera': 1861, 'cela': 376, 'dinterogasi': 505, 'dbd': 440, 'muntaber': 1338, 'ghufron': 657, 'libat': 1139, 'mang': 1210, 'teliti': 2100, 'akademisi': 35, 'siloam': 1946, 'semlat': 1894, 'asma': 132, 'dibedain': 475, 'pelayanya': 1538, 'jutek': 884, 'arogan': 121, 'nyawa': 1432, 'taruh': 2084, 'saiful': 1801, 'anwar': 103, 'malang': 1196, 'insya': 789, 'meberi': 1250, 'rizky': 1768, 'limpah': 1143, 'barokah': 199, 'praktis': 1638, 'kepala': 971, 'sub': 2021, 'bendahara': 244, 'bnk': 298, 'giat': 659, 'sosialisasi': 1993, 'pnpn': 1619, 'pns': 1620, 'polewali': 1626, 'mandar': 1203, 'itung': 805, 'debet': 441, 'asi': 128, 'konsep': 1042, 'palakin': 1486, 'bubar': 326, 'becus': 218, 'tumpuk': 2197, 'ras': 1716, 'larang': 1110, 'nabung': 1345, 'dana': 429, 'takut': 2063, 'patut': 1520, 'apresiasi': 115, 'tenaga': 2109, 'pembayaranya': 1543, 'outsourcing': 1469, 'work': 2304, 'berkas': 259, 'magang': 1174, 'bakti': 173, 'kode': 1028, 'darimana': 433, 'aturanya': 141, 'bila': 281, 'harta': 702, 'ngomongin': 1400, 'panjang': 1498, 'dar': 431, 'pengurusanya': 1555, 'legalisir': 1123, 'siap': 1935, 'bas': 201, 'bokap': 305, 'jaman': 830, 'cuk': 416, 'birokrasi': 285, 'internal': 793, 'akal': 36, 'haji': 686, 'mlah': 1301, 'standardisasi': 2008, 'dsuruh': 549, 'nyusahin': 1438, 'pnh': 1618, 'bkin': 290, 'sbuah': 1839, 'tlong': 2163, 'perspektif': 1586, 'sgala': 1931, 'sabar': 1796, 'juang': 872, 'buah': 324, 'paruh': 1506, 'sedih': 1857, 'tunjang': 2202, 'persoalanya': 1584, 'operator': 1456, 'rumit': 1789, 'tiket': 2142, 'kereta': 981, 'api': 110, 'paytren': 1522, 'untung': 2232, 'ugm': 2212, 'didapatapi': 479, 'ketenagakerjan': 996, 'manfatnya': 1209, 'haha': 684, 'serah': 1915, 'pasrah': 1514, 'obrol': 1443, 'spesial': 1998, 'klungkung': 1020, 'ely': 570, 'widiani': 2287, 'selaku': 1876, 'wayan': 2281, 'bidang': 278, 'industrial': 773, 'jamsostek': 832, 'dinas': 500, 'gianyar': 658, 'jatuh': 841, 'tanggal': 2071, 'bersihin': 263, 'karang': 921, 'andil': 88, 'silang': 1944, 'at': 136, 'least': 1119, 'segi': 1862, 'minim': 1287, 'yogyakarta': 2320, 'sop': 1987, 'subang': 2022, 'ngurusin': 1404, 'ae': 19, 'acara': 5, 'bacot': 158, 'vbac': 2255, 'andal': 87, 'hendak': 717, 'test': 2127, 'wahai': 2267, 'merdeka': 1273, 'jajah': 822, 'modal': 1308, 'pantas': 1499, 'inhil': 780, 'inovasi': 782, 'pancasila': 1490, 'posisi': 1632, 'sungsang': 2030, 'st': 2003, 'yusup': 2325, 'yauda': 2315, 'sndiri': 1974, 'bingung': 284, 'rahim': 1700, 'rsup': 1780, 'karyadi': 925, 'strategi': 2017, 'retensi': 1752, 'usage': 2242, 'iklas': 761, 'fotocopy': 619, 'elah': 568, 'cb': 371, 'sopan': 1988, 'bun': 341, 'kenal': 964, 'servicenya': 1923, 'zonk': 2328, 'gonta': 671, 'senyum': 1908, 'prudential': 1665, 'genjet': 654, 'hospital': 733, 'makasar': 1185, 'kista': 1012, 'kuret': 1080, 'bedabedain': 220, 'cesar': 379, 'khianat': 1005, 'silinder': 1945, 'karat': 922, 'prihatin': 1648, 'daerah': 422, 'pelayanany': 1536, 'dijakarta': 487, 'jawasaya': 846, 'azan': 155, 'prawiro': 1639, 'telegram': 2099, 'chika': 384, 'rimas': 1764, 'bales': 176, 'golong': 670, 'tujuanya': 2190, 'premi': 1642, 'rang': 1710, 'kebijkan': 942, 'diakalin': 467, 'budak': 328, 'didzolimi': 481, 'jujur': 875, 'dukung': 555, 'microtransaction': 1280, 'blablabla': 291, 'hampir': 693, 'tiga': 2141, 'beberapa': 217, 'empat': 576, 'bedebah': 224, 'rerata': 1745, 'doktrin': 535, 'nangepinya': 1360, 'buang': 325, 'sempurna': 1898, 'ekonomi': 566, 'mrmang': 1324, 'sedgkn': 1855, 'pindh': 1601, 'rezim': 1756, 'makansaja': 1183, 'repot': 1742, 'rsupn': 1781, 'cipto': 395, 'mangunkusumo': 1211, 'ring': 1766, 'fatmawati': 600, 'dng': 530, 'taiwan': 2062, 'lapor': 1109, 'registerasi': 1728, 'datengin': 439, 'kendala': 967, 'nangung': 1361, 'berat': 254, 'ckckck': 399, 'lurah': 1169, 'lempar': 1130, 'iniamin': 781, 'hikmah': 725, 'segar': 1860, 'bugar': 331, 'waras': 2277, 'bahagia': 164, 'pertangungan': 1588, 'mail': 1178, 'whatsapnya': 2285, 'maintenance': 1180, 'sosmed': 1994, 'dm': 528, 'ig': 757, 'twiter': 2207, 'responsif': 1750, 'kontak': 1045, 'dikerjain': 492, 'sja': 1960, 'wong': 2303, 'ujung': 2216, 'wkwkwkwkwkw': 2298, 'pk': 1607, 'bpjsku': 314, 'jasa': 839, 'transparan': 2176, 'customer': 419, 'provider': 1663, 'aliram': 66, 'bayaraja': 212, 'te': 2092, 'kepake': 970, 'saling': 1811, 'mbantu': 1247, 'lhiran': 1138, 'dirwt': 513, 'diagnosa': 465, 'ispa': 801, 'lekosit': 1125, 'justru': 881, 'screning': 1843, 'neonatal': 1378, 'wacana': 2264, 'tangungan': 2073, 'sangkut': 1821, 'depan': 453, 'tisu': 2158, 'basah': 202, 'kering': 982, 'soft': 1979, 'mamy': 1201, 'poko': 1622, 'balut': 178, 'maternity': 1238, 'puluh': 1678, 'imbas': 765, 'jarang': 837, 'qadarulah': 1692, 'bolakbalik': 307, 'mas': 1225, 'ngelap': 1394, 'lensa': 1133, 'wkwk': 2295, 'kamis': 907, 'kejaksan': 948, 'padang': 1474, 'sidempuan': 1937, 'laksana': 1090, 'kc': 938, 'upa': 2234, 'pemangilan': 1542, 'mediasi': 1252, 'negoisasi': 1373, 'patuh': 1519, 'mbah': 1246, 'mu': 1325, 'minum': 1290, 'maksimum': 1191, 'ragu': 1697, 'tante': 2076, 'alhasil': 62, 'senak': 1900, 'sekarwangi': 1872, 'sukabumi': 2026, 'hehehehehe': 713, 'grade': 674, 'halang': 688, 'autoimun': 145, 'bakal': 172, 'dibayrkan': 474, 'mal': 1193, 'kanal': 912, 'tatap': 2088, 'care': 367, 'center': 377, 'bentrok': 248, 'momy': 1316, 'sayidah': 1835, 'jaktim': 825, 'sembarang': 1889, 'korlantas': 1055, 'raharja': 1698, 'tinjau': 2153, 'polres': 1629, 'purwakarta': 1683, 'progres': 1658, 'kesiap': 992, 'uji': 2215, 'da': 421, 'gambar': 633, 'ibe': 749, 'ibadah': 747, 'even': 584, 'apkasi': 111, 'otonomi': 1467, 'expo': 586, 'tolak': 2170, 'dalih': 428, 'icu': 751, 'double': 541, 'gprnah': 673, 'sistemny': 1958, 'ky': 1082, 'urun': 2239, 'bajing': 171, 'dimainin': 496, 'pasuk': 1516, 'statmin': 2010, 'mimin': 1284, 'colab': 403, 'sobat': 1977, 'kuis': 1075, 'berkat': 260, 'taat': 2054, 'listrik': 1149, 'motor': 1320, 'korden': 1052, 'kloset': 1018, 'sentuh': 1906, 'menu': 1271, 'fotokopi': 620, 'security': 1851, 'informatif': 777, 'bantuin': 192, 'ngarahin': 1389, 'download': 542, 'step': 2013, 'lanjutanya': 1102, 'dijutekin': 490, 'markotop': 1220, 'sesal': 1924, 'siapa': 1936, 'beliau': 237, 'rontgen': 1769, 'kurg': 1081, 'awar': 147, 'neneku': 1376, 'perawatany': 1566, 'nenek': 1375, 'abet': 2, 'suntik': 2031, 'insulin': 787, 'wlaupun': 2300, 'kdg': 940, 'pokok': 1623, 'lawa': 1114, 'fikir': 606, 'disalahgunakan': 514, 'absah': 4, 'fc': 603, 'walohualam': 2274, 'slip': 1966, 'supir': 2033, 'sekian': 1873, 'waduh': 2265, 'kasihan': 931, 'pu': 1670, 'khala': 1003, 'atitute': 138, 'induk': 772, 'identitas': 755, 'ake': 37, 'diskriminasi': 517, 'teteh': 2131, 'agama': 21, 'calon': 364, 'jamah': 829, 'aktid': 43, 'elain': 569, 'instruksi': 786, 'kapolri': 920, 'penyempurnan': 1561, 'regulasi': 1729, 'soliditas': 1983, 'optimal': 1461, 'gelar': 653, 'sinergikamtibmas': 1950, 'webiste': 2282, 'maret': 1216, 'gubris': 678, 'terap': 2115, 'photocopy': 1595, 'terlalu': 2123, 'guys': 679, 'beritajogja': 257, 'jogjaistimewa': 865, 'gabayar': 628, 'ditaro': 522, 'ketimbang': 1001, 'korelasi': 1054, 'dimna': 499, 'alih': 64, 'pbpu': 1526, 'tungakanya': 2200, 'esc': 581, 'hem': 715, 'spog': 2000, 'mnta': 1304, 'jatah': 840, 'abrek': 3, 'ganguan': 636, 'ivf': 810, 'ivan': 809, 'indonesiabisa': 771, 'bohong': 304, 'tetes': 2132, 'keringat': 983, 'kalu': 905, 'namba': 1354, 'operasional': 1455, 'senin': 1904, 'jumat': 877, 'pukul': 1675, 'wib': 2286, 'dftar': 463, 'mengahapus': 1263, 'kepersertan': 974, 'resti': 1751, 'mulya': 1333, 'adi': 12, 'difaskes': 482, 'masyaallah': 1231, 'dipostingan': 508, 'infused': 778, 'huhu': 741, 'kepercayan': 973, 'komersial': 1033, 'sisi': 1956, 'kerap': 979, 'sandera': 1818, 'target': 2081, 'farmasi': 595, 'tekan': 2096, 'tangerang': 2069, 'pulau': 1677, 'jawa': 844, 'yampun': 2313, 'cadang': 358, 'lairan': 1088, 'maksd': 1189, 'layananya': 1117, 'saraf': 1823, 'formulasi': 617, 'masyrakatat': 1234, 'matur': 1240, 'nuwun': 1426, 'dok': 533, 'nyekek': 1433, 'gausa': 645, 'banting': 190, 'tasik': 2086, 'ciamis': 386, 'banjar': 187, 'pangandaran': 1494, 'hai': 685, 'ijin': 759, 'sep': 1909, 'sidik': 1938, 'jari': 838, 'lemas': 1128, 'bedrest': 225, 'mabok': 1172, 'tds': 2091, 'eh': 564, 'the': 2135, 'brti': 321, 'gasadar': 642, 'metro': 1278, 'cikupa': 390, 'permintan': 1579, 'selai': 1875, 'keluhanya': 956, 'mengcover': 1264, 'bibi': 275, 'vonis': 2262, 'payudara': 1523, 'kemoterapi': 960, 'dewan': 460, 'djsn': 524, 'eka': 565, 'putri': 1690, 'banding': 179, 'pendapatanya': 1550, 'dapt': 430, 'kesanya': 987, 'tipu': 2155, 'ane': 89, 'wkqkqk': 2294, 'meminimalisir': 1259, 'hrg': 737, 'drp': 546, 'yo': 2318, 'dianaktirikan': 469, 'true': 2183, 'sepupu': 1913, 'cedera': 372, 'nangani': 1359, 'sejahtera': 1867, 'saldo': 1808, 'akumulasi': 48, 'aya': 152, 'segitu': 1863, 'ne': 1369, 'megap': 1254, 'ey': 587, 'bepjrs': 251, 'sing': 1951, 'pret': 1646, 'vaksin': 2254, 'skarang': 1961, 'tai': 2061, 'efektif': 562, 'korantempo': 1050, 'maksud': 1192, 'banten': 189, 'tegal': 2095, 'tengah': 2110, 'ektp': 567, 'sampah': 1816, 'ad': 10, 'tulis': 2192, 'okt': 1447, 'kuno': 1078, 'upaya': 2235, 'nang': 1358, 'thread': 2137, 'persis': 1583, 'mamih': 1198, 'grgr': 676, 'spu': 2002, 'selurih': 1885, 'dagang': 425, 'desember': 458, 'akses': 42, 'jember': 854, 'aduh': 18, 'telp': 2102, 'kolaborasi': 1030, 'potret': 1636, 'gbs': 648, 'goblok': 668, 'ptfi': 1669, 'instansi': 785, 'civitas': 398, 'akademika': 34, 'airlanga': 27, 'memanfatkan': 1257, 'basis': 203, 'rahayu': 1699, 'yakum': 2312, 'alami': 53, 'sdikit': 1846, 'mngurus': 1303, 'overal': 1470, 'bahwasanya': 168, 'bocor': 300, 'alat': 58, 'bodhi': 301, 'semprul': 1897, 'sugondo': 2024, 'suwarno': 2045, 'ungar': 2226, 'psikolog': 1667, 'diarahin': 471, 'semangat': 1887, 'andai': 86, 'belit': 239, 'rajin': 1703, 'fatal': 599, 'rembusnya': 1739, 'entah': 578, 'kr': 1062, 'pasu': 1515, 'hrd': 736, 'amp': 79, 'unuk': 2233, 'catat': 370, 'rutinin': 1794, 'judul': 874, 'ng': 1381, 'gingivitis': 664, 'akut': 49, 'dzalimnya': 560, 'department': 454, 'pasilitas': 1513, 'lega': 1122, 'materai': 1237, 'kini': 1007, 'puskesos': 1689, 'desa': 457, 'cisewu': 396, 'skip': 1964, 'kampus': 909, 'awokwokwok': 151, 'apalgi': 107, 'gaptek': 641, 'kuasa': 1074, 'bego': 228, 'ngerepotin': 1398, 'rakayat': 1704, 'tanjung': 2075, 'priok': 1653, 'byangkan': 352, 'kcuali': 939, 'lantas': 1105, 'onlinenya': 1452, 'alir': 65, 'harapanya': 698, 'lapis': 1108, 'amanah': 74, 'metode': 1277, 'kouta': 1060, 'matang': 1236, 'laba': 1084, 'sok': 1982, 'razim': 1721, 'duh': 552, 'sperti': 1997, 'hidayah': 723, 'specialis': 1996, 'syaraf': 2048, 'sogok': 1980, 'idung': 756, 'kasar': 928, 'nanyanya': 1364, 'judes': 873, 'resin': 1748, 'nerima': 1379, 'upgrade': 2237, 'format': 615, 'yt': 2323, 'ngalami': 1384, 'kakek': 898, 'faktor': 593, 'dibikinin': 476, 'tingalnya': 2149, 'kos': 1058, 'begimana': 226, 'wkwkwkwkwkwk': 2299, 'komunikasi': 1038, 'agenda': 22, 'konsentrasi': 1041, 'malam': 1195, 'apotik': 114, 'sptnya': 2001, 'naikin': 1350, 'jerit': 858, 'waw': 2280, 'gabsa': 629, 'dijadin': 485, 'negatif': 1371, 'ahahahahah': 24, 'radiasi': 1695, 'stop': 2016, 'dlnya': 527, 'just': 880, 'diceritain': 477, 'dosen': 540, 'sdf': 1845, 'rek': 1733, 'geraham': 655, 'kiri': 1009, 'lubang': 1162, 'kanan': 913, 'cont': 406, 'jutan': 883, 'ragara': 1696, 'caleg': 362, 'calegnya': 363, 'dibayarin': 473, 'taun': 2089, 'ide': 753, 'pngin': 1617, 'santet': 1822, 'awet': 150, 'kabar': 885, 'cobain': 402, 'obgyn': 1441, 'blokir': 295, 'syarate': 2050, 'diaktifin': 468, 'bayangin': 210, 'amsyong': 83, 'juli': 876, 'rincianya': 1765, 'audit': 142, 'dokumen': 536, 'isyarat': 803, 'you': 2321, 'hoax': 732, 'max': 1244, 'ongkos': 1450, 'mondar': 1317, 'mandir': 1205, 'wkwkw': 2296, 'kaper': 919, 'faeshol': 589, 'ucap': 2210, 'pangkalpinang': 1496, 'wujud': 2308, 'bangka': 183, 'belitung': 241, 'akibat': 40, 'proyek': 1664, 'korban': 1051, 'moral': 1318, 'tiba': 2140, 'optimis': 1462, 'daster': 436, 'sigle': 1940, 'fighter': 605, 'parents': 1504, 'tangga': 2070, 'turunya': 2205, 'rsia': 1776, 'dj': 523, 'hatur': 708, 'nuhun': 1422, 'duta': 559, 'republik': 1743, 'vice': 2257, 'marshal': 1224, 'mohamad': 1313, 'mostafizur': 1319, 'rahman': 1701, 'unjung': 2230, 'dikeluarin': 491, 'pertimbangin': 1589, 'personal': 1585, 'insurance': 788, 'lingkunganya': 1145, 'move': 1321, 'on': 1449, 'apotek': 113, 'tcm': 2090, 'herbal': 720, 'efek': 561, 'khasiat': 1004, 'walopun': 2275, 'coment': 405, 'menangung': 1261, 'pangil': 1495, 'jpn': 868, 'komitmen': 1034, 'artikel': 123, 'beuh': 270, 'seribet': 1918, 'jelasin': 851, 'saking': 1802, 'haru': 703, 'sakti': 1805, 'telusur': 2103, 'coveran': 410, 'flek': 612, 'sbnrx': 1837, 'triplets': 2181, 'dijauhakn': 489, 'salih': 1809, 'pelaksanan': 1532, 'bodohin': 303, 'anterin': 98, 'moewardi': 1311, 'lup': 1166, 'sarana': 1825, 'sengaknya': 1903, 'atleast': 139, 'woy': 2305, 'amet': 77, 'triliun': 2178, 'juntrung': 879, 'neng': 1377, 'koreksi': 1053, 'mis': 1294, 'usa': 2241, 'team': 2093, 'tangap': 2068, 'happy': 695, 'frekuensi': 625, 'diare': 472, 'kadang': 890, 'ri': 1757, 'selaras': 1880, 'cros': 414, 'berangapan': 252, 'mutusin': 1344, 'masyarkat': 1233, 'ngaknya': 1383, 'healthkathon': 710, 'event': 585, 'hackathon': 681, 'sasar': 1827, 'ruwet': 1795, 'modus': 1310, 'fakta': 592, 'mcs': 1249, 'kecamatanselakau': 944, 'tipe': 2154, 'bangakan': 181, 'lambat': 1095, 'dunia': 558, 'maju': 1181, 'revisi': 1753, 'cha': 381, 'ideal': 754, 'alasanya': 57, 'maks': 1188, 'bumil': 340, 'dirujuj': 512, 'smec': 1969, 'itc': 804, 'pas': 1507, 'observasi': 1444, 'ancam': 85, 'sakratul': 1804, 'maut': 1243, 'layanin': 1118, 'tindas': 2147, 'gaya': 647, 'saus': 1832, 'krim': 1064, 'lauk': 1113, 'kerang': 978, 'kuah': 1071, 'naman': 1353, 'loyal': 1159, 'iseng': 799, 'cintak': 394, 'bahu': 167, 'rampas': 1708, 'gbsa': 649, 'fakses': 591, 'ferguso': 604, 'pasal': 1508, 'acu': 8, 'adu': 17, 'argumen': 119, 'ditanguhkan': 520, 'geta': 656, 'margonda': 1217, 'faty': 601, 'liver': 1150, 'super': 2032, 'lemah': 1127, 'drop': 545, 'soreh': 1990, 'tlng': 2162, 'arif': 120, 'bijaksana': 280, 'interaksi': 791, 'kenan': 965, 'nano': 1362, 'gejala': 652, 'dehidrasi': 445, 'batpil': 206, 'tercover': 2117, 'check': 383, 'sms': 1972, 'gateway': 644, 'flat': 611, 'fisik': 607, 'mental': 1268, 'ilnes': 763, 'psikiater': 1666, 'lokitacare': 1157, 'youmaterstartnow': 2322, 'mentalsehatitupenting': 1269, 'bal': 174, 'jimbaran': 860, 'bdg': 214, 'sltn': 1967, 'tertib': 2124, 'efisien': 563, 'tk': 2159, 'pingpong': 1602, 'sungguh': 2029, 'ktnya': 1068, 'men': 1260, 'dobel': 532, 'transfer': 2174, 'teknis': 2097, 'biarpun': 272, 'pinjeman': 1603, 'bank': 188, 'timbang': 2144, 'prosesur': 1661, 'wilasa': 2290, 'semarang': 1888, 'rantau': 1713, 'klik': 1016, 'smartphone': 1968, 'esco': 582, 'taruhanya': 2085, 'kadek': 891, 'maharani': 1176, 'nuansa': 1421, 'swasti': 2047, 'muda': 1328, 'pekerjan': 1531, 'rumahny': 1788, 'ngikutin': 1399, 'segmen': 1864, 'bersihini': 264, 'nyentuh': 1435, 'alesanya': 60, 'alzeimer': 71, 'parkinson': 1505, 'kesukarelan': 994, 'mampus': 1200, 'mksih': 1300, 'kesejahteran': 990, 'korpri': 1056, 'bpjskesehatanri': 312, 'bpjskesmelayaninegeri': 313, 'dengangotongroyongsemuatertolong': 451, 'beritakita': 258, 'foya': 621, 'dilayanikok': 494, 'mayapada': 1245, 'pol': 1624, 'yakali': 2310, 'sayasangat': 1834, 'positif': 1633, 'pura': 1681, 'ngambil': 1386, 'cuti': 420, 'ting': 2148, 'caesar': 359, 'sabtu': 1797, 'dini': 502, 'nyut': 1439}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vect.vocabulary_) #jumlah term dalam bentuk vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2329"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_vect.vocabulary_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KNN = KNeighborsClassifier(n_neighbors=3) #inisialisasi dengan k=3\n",
    "KNN4no = model_KNN.fit(train_X_tfidf,y_train) #melatih model knn menggunakan data pelatihan\n",
    "\n",
    "y_pred_KNN2 = KNN4no.predict(test_X_tfidf) #melakukan prediksi model knn yang telah dilatih\n",
    "# y_prob_KNN2 = KNN2.decision_function(test_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.8047619047619048\n",
      "Waktu Pelatihan: 0.0 detik\n",
      "Waktu Prediksi: 0.05445432662963867 detik\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Inisialisasi model KNN dengan 3 tetangga terdekat\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Training model KNN\n",
    "start_time = time.time()\n",
    "KNN4no = model_KNN.fit(train_X_tfidf, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Prediksi dengan model KNN\n",
    "start_time = time.time()\n",
    "y_pred_KNN2 = KNN4no.predict(test_X_tfidf)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Mengukur akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred_KNN2)\n",
    "\n",
    "print(\"Akurasi:\", accuracy)\n",
    "print(\"Waktu Pelatihan:\", training_time, \"detik\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.79      0.79        62\n",
      "           0       0.77      0.88      0.82        72\n",
      "           1       0.86      0.75      0.80        76\n",
      "\n",
      "    accuracy                           0.80       210\n",
      "   macro avg       0.81      0.81      0.80       210\n",
      "weighted avg       0.81      0.80      0.80       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = model_KNN.predict(test_X_tfidf)\n",
    "\n",
    "CM = confusion_matrix(y_test, predicted)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.14\n",
      "\n",
      "Precision:  0.7812534365135932\n",
      "\n",
      "Recall:  0.7714285714285715\n",
      "\n",
      "F1-Score:  0.771559561409793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_KNN2 = accuracy_score(df_test['Sentiments'], y_pred_KNN2)\n",
    "precision_KNN2 = precision_score(df_test['Sentiments'], y_pred_KNN2, average='weighted')\n",
    "recall_KNN2 = recall_score(df_test['Sentiments'], y_pred_KNN2, average='weighted')\n",
    "f1_KNN2 = f1_score(df_test['Sentiments'], y_pred_KNN2, average='weighted')\n",
    "\n",
    "# Result\n",
    "print(\"Accuracy: {:.2f}\".format(acc_KNN2*100),end='\\n\\n')\n",
    "print(\"Precision: \", precision_KNN2,end='\\n\\n')\n",
    "print(\"Recall: \", recall_KNN2,end='\\n\\n')\n",
    "print(\"F1-Score: \", f1_KNN2,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  7,  6],\n",
       "       [ 6, 63,  3],\n",
       "       [ 7, 12, 57]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_KNN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KNN3_no.sav', 'wb') as f: #k=3\n",
    "    pickle.dump(KNN4no, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KNN4_full.sav', 'wb') as f: #k=4\n",
    "    pickle.dump(KNN4, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "model_NB = ComplementNB() #inisialiasi library\n",
    "train_X_tfidf = train_X_tfidf.todense() #mengubah representasi menjadi matrix dense atau matrix padat supaya matrixnya tidak nol terlalu banyak\n",
    "test_X_tfidf = test_X_tfidf.todense()\n",
    "\n",
    "# Training \n",
    "NB2 = model_NB.fit(train_X_tfidf,y_train) #melatih model menggunakan data pelatihan\n",
    "\n",
    "# Evaluation\n",
    "y_pred_nb2 = NB2.predict(test_X_tfidf) #melakukan prediksi\n",
    "y_prob_nb2 = NB2.predict_proba(test_X_tfidf) #melakukan prediksi probabilitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.8714285714285714\n",
      "Waktu Pelatihan: 0.05601978302001953 detik\n",
      "Waktu Prediksi: 0.007994890213012695 detik\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Inisialisasi model Naive Bayes\n",
    "model_NB = ComplementNB()\n",
    "\n",
    "# Konversi matriks TF-IDF ke matriks dense\n",
    "train_X_tfidf = train_X_tfidf.todense()\n",
    "test_X_tfidf = test_X_tfidf.todense()\n",
    "\n",
    "# Training model\n",
    "start_time = time.time()\n",
    "NB2 = model_NB.fit(train_X_tfidf, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Evaluasi model\n",
    "start_time = time.time()\n",
    "y_pred_nb2 = NB2.predict(test_X_tfidf)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Mengukur akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred_nb2)\n",
    "\n",
    "print(\"Akurasi:\", accuracy)\n",
    "print(\"Waktu Pelatihan:\", training_time, \"detik\")\n",
    "print(\"Waktu Prediksi:\", inference_time, \"detik\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.82      0.84        62\n",
      "           0       0.87      0.94      0.91        72\n",
      "           1       0.86      0.83      0.85        76\n",
      "\n",
      "    accuracy                           0.87       210\n",
      "   macro avg       0.87      0.87      0.87       210\n",
      "weighted avg       0.87      0.87      0.87       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = model_NB.predict(test_X_tfidf)\n",
    "\n",
    "CM = confusion_matrix(y_test, predicted)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function Accuration NB 1\n",
    "\n",
    "# acc_NB1 = accuracy_score(df_test['Label'], y_pred_nb)\n",
    "# precision_NB1 = precision_score(df_test['Label'], y_pred_nb, average='weighted')\n",
    "# recall_NB1 = recall_score(df_test['Label'], y_pred_nb, average='weighted')\n",
    "# f1_NB1 = f1_score(df_test['Label'], y_pred_nb, average='weighted')\n",
    "\n",
    "# # Result\n",
    "# print(\"Accuracy: {:.2f}\".format(acc_NB1*100),end='\\n\\n')\n",
    "# print(\"Precision: \", precision_NB1,end='\\n\\n')\n",
    "# print(\"Recall: \", recall_NB1,end='\\n\\n')\n",
    "# print(\"F1-Score: \", f1_NB1,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.67\n",
      "\n",
      "Precision:  0.8664356771624011\n",
      "\n",
      "Recall:  0.8666666666666667\n",
      "\n",
      "F1-Score:  0.8657758056464584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function Accuration NB 2\n",
    "\n",
    "acc_NB2 = accuracy_score(df_test['Sentiments'], y_pred_nb2)\n",
    "precision_NB2 = precision_score(df_test['Sentiments'], y_pred_nb2, average='weighted')\n",
    "recall_NB2 = recall_score(df_test['Sentiments'], y_pred_nb2, average='weighted')\n",
    "f1_NB2 = f1_score(df_test['Sentiments'], y_pred_nb2, average='weighted')\n",
    "\n",
    "# Result\n",
    "print(\"Accuracy: {:.2f}\".format(acc_NB2*100),end='\\n\\n')\n",
    "print(\"Precision: \", precision_NB2,end='\\n\\n')\n",
    "print(\"Recall: \", recall_NB2,end='\\n\\n')\n",
    "print(\"F1-Score: \", f1_NB2,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  3,  8],\n",
       "       [ 2, 68,  2],\n",
       "       [ 6,  7, 63]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle\n",
    "pickle.dump(NB2,open(\"NB1_no.sav\",\"wb\"))\n",
    "# with open('NB2_full.sav', 'wb') as f:\n",
    "#     pickle.dump(NB2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.8857142857142857\n",
      "Waktu Pelatihan: 11.255311965942383 detik\n",
      "Waktu Prediksi: 2.510164499282837 detik\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Inisialisasi model SVM\n",
    "model_SVM = SVC()\n",
    "\n",
    "# Training model SVM\n",
    "start_time = time.time()\n",
    "SVM_model = model_SVM.fit(train_X_tfidf, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Prediksi dengan model SVM\n",
    "start_time = time.time()\n",
    "y_pred_SVM = SVM_model.predict(test_X_tfidf)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Mengukur akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred_SVM)\n",
    "\n",
    "print(\"Akurasi:\", accuracy)\n",
    "print(\"Waktu Pelatihan:\", training_time, \"detik\")\n",
    "# print(\"Waktu Prediksi:\", inference_time, \"detik\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Creating  a confusion matrix,which compares the y_test and y_pred\n",
    "cm = confusion_matrix(df_test['sentiment'], y_pred_nb)\n",
    "\n",
    "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
    "cm_df = pd.DataFrame(cm)\n",
    "\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['Positif', 'Netral', 'Negatif']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tugas_Akhir.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e5b705084e86d764c57f58bcbe1f1ea3778e3281a0fcf888f61d7a501a99b833"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
